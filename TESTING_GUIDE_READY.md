# üß™ COMPREHENSIVE TESTING GUIDE

**Status:** ‚úÖ Database Fixed - Ready for Testing  
**Date:** January 7, 2026

---

## üéØ WHAT WAS FIXED

‚úÖ Database migration records cleaned up  
‚úÖ `locked_by` and `locked_at` columns added  
‚úÖ All indexes and constraints in place  
‚úÖ Migration state matches codebase  
‚úÖ Server will start cleanly on next deploy

---

## üöÄ STEP 1: VERIFY DEPLOYMENT

### Check Server Logs (Render Dashboard)
Look for these success messages:

```
‚úÖ Expected logs:
[Monlam Tracking] App initializing...
[Monlam Filter] ‚úÖ Added monlam_tracking.filters.AnnotationVisibilityFilter
[Monlam Tracking] ‚úÖ Visibility filter registered
[Monlam Signals] ‚úÖ Connected tracking for Category
[Monlam Signals] ‚úÖ Connected tracking for Span
[Monlam Signals] ‚úÖ Connected tracking for TextLabel
[Monlam Tracking] ‚úÖ Auto-tracking signals connected
```

### Check Migration Status
If you have access to Render Shell:
```bash
python manage.py showmigrations assignment
```

Expected output:
```
assignment
 [X] 0001_initial
 [X] 0002_completion_tracking
 [X] 0003_example_locking
 [X] 0006_annotation_tracking_simple  ‚Üê Should be checked ‚úÖ
```

---

## üß™ STEP 2: TEST DATASET TABLE COLUMNS

### 2.1 Access Dataset Page
1. Login to Doccano
2. Navigate to your project
3. Click "‡ΩÇ‡Ωû‡Ω≤‡ºã‡ΩÇ‡æ≤‡ΩÑ‡Ω¶‡ºç" (Dataset) in left menu

### 2.2 Verify Columns Appear
Check for these columns in order:

| Position | Column Name    | What to Check                          |
|----------|----------------|----------------------------------------|
| 1        | ID             | (Original)                             |
| 2        | Text/Data      | (Original)                             |
| 3        | (Original)     | (Original)                             |
| 4        | **Annotated By** | ‚úÖ Should show username or "N/A"       |
| 5        | **Reviewed By**  | ‚úÖ Should show username or "N/A"       |
| 6        | **Status**       | ‚úÖ Should show pending/submitted/etc.  |

### 2.3 Check Data
- ‚úÖ Columns are aligned (no data shifting)
- ‚úÖ Headers match data
- ‚úÖ Status shows correct values: `pending`, `submitted`, `approved`, `rejected`

---

## üîí STEP 3: TEST VISIBILITY FILTERING

### Setup: Create Test Users
You need 3 users with different roles:

1. **Annotator A** (role: `annotator`)
2. **Annotator B** (role: `annotator`)
3. **Reviewer** (role: `approver` or `project_manager`)

### Test 3.1: Annotator A Workflow

```
1. Login as Annotator A
2. Go to project dataset
3. Count examples visible: _____ (note this number)

4. Click "Start Annotation" or click on first example
5. Add an annotation (label/text/etc.)
6. Save the annotation

7. Go back to dataset page
8. Count examples visible: _____ (should be 1 less than before)
9. The example you just annotated should NOT be visible ‚úÖ
```

**Expected Result:**
- ‚úÖ After annotation, that example disappears from Annotator A's view
- ‚úÖ Status in database is now `submitted`
- ‚úÖ `annotated_by` shows Annotator A's username

### Test 3.2: Annotator B Cannot See Annotator A's Work

```
1. Login as Annotator B
2. Go to project dataset
3. The example that Annotator A just annotated should NOT be visible ‚úÖ
4. Annotator B should only see unannotated examples
```

**Expected Result:**
- ‚úÖ Annotator B does NOT see examples annotated by Annotator A
- ‚úÖ Prevents double-editing and confusion

### Test 3.3: Reviewer Can See Everything

```
1. Login as Reviewer
2. Go to project dataset
3. Should see ALL examples, including:
   - ‚úÖ Unannotated (pending)
   - ‚úÖ Annotated by Annotator A (submitted)
   - ‚úÖ Annotated by Annotator B (submitted)
   - ‚úÖ Previously approved examples
   - ‚úÖ Previously rejected examples
```

**Expected Result:**
- ‚úÖ Reviewer has full visibility
- ‚úÖ Can review any example regardless of status

### Test 3.4: Rejection Flow

```
1. As Reviewer, reject the example annotated by Annotator A
   (Use approval buttons if visible, or mark as rejected)

2. Logout, login as Annotator A
3. Go to project dataset
4. The rejected example should NOW be visible to Annotator A ‚úÖ
5. Status should show "rejected" in column 6

6. Logout, login as Annotator B
7. The rejected example should NOT be visible to Annotator B ‚úÖ
```

**Expected Result:**
- ‚úÖ Rejected examples are visible ONLY to the original annotator
- ‚úÖ Other annotators still can't see them
- ‚úÖ This allows re-work without confusion

---

## üîê STEP 4: TEST EXAMPLE LOCKING

### Test 4.1: Basic Locking

```
1. Login as Annotator A
2. Open an example for annotation
3. Check database (or use Django admin):
   - annotation_tracking table
   - Find record for this example
   - locked_by_id should be Annotator A's user ID ‚úÖ
   - locked_at should be current timestamp ‚úÖ

4. In another browser/incognito window, login as Annotator B
5. Try to open the SAME example
   - Should see "locked" message or cannot edit ‚úÖ

6. As Annotator A, close/save the example
7. Check database again:
   - locked_by_id should be NULL ‚úÖ
   - locked_at should be NULL ‚úÖ

8. As Annotator B, try to open the example again
   - Should now be able to edit ‚úÖ
```

**Expected Result:**
- ‚úÖ Only one user can edit an example at a time
- ‚úÖ Lock is released when user saves/closes
- ‚úÖ Prevents simultaneous editing conflicts

### Test 4.2: Lock Timeout (if implemented)

```
1. As Annotator A, open an example
2. Wait for lock timeout period (e.g., 15 minutes)
3. Check database:
   - locked_at timestamp is > 15 minutes ago
   - System should auto-release the lock ‚úÖ

4. As Annotator B, try to open the example
   - Should now be able to edit ‚úÖ
```

**Note:** Lock timeout may not be implemented yet. If not, that's a future enhancement.

---

## üìä STEP 5: TEST AUTO-TRACKING

### Test 5.1: Annotation Tracking

```
1. Login as Annotator A
2. Annotate Example #50 (or any example)
3. Save the annotation

4. Check dataset table:
   - Column 4 (Annotated By): "Annotator A" ‚úÖ
   - Column 5 (Reviewed By): "N/A" ‚úÖ
   - Column 6 (Status): "submitted" ‚úÖ

5. Check database directly:
   SELECT * FROM annotation_tracking WHERE example_id = 50;
   
   Expected:
   - project_id: (your project ID)
   - example_id: 50
   - annotated_by_id: (Annotator A's user ID) ‚úÖ
   - annotated_at: (timestamp when saved) ‚úÖ
   - reviewed_by_id: NULL
   - reviewed_at: NULL
   - status: 'submitted' ‚úÖ
   - review_notes: ''
   - locked_by_id: NULL (after saving)
   - locked_at: NULL
```

**Expected Result:**
- ‚úÖ Tracking record created automatically
- ‚úÖ No manual intervention needed
- ‚úÖ Data shows in dataset table

### Test 5.2: Review Tracking

```
1. Login as Reviewer
2. Find Example #50 (the one Annotator A annotated)
3. Approve the annotation
   (If approve buttons exist, click "Approve")

4. Check dataset table:
   - Column 4 (Annotated By): "Annotator A" ‚úÖ
   - Column 5 (Reviewed By): "Reviewer" ‚úÖ
   - Column 6 (Status): "approved" ‚úÖ

5. Check database:
   SELECT * FROM annotation_tracking WHERE example_id = 50;
   
   Expected:
   - annotated_by_id: (Annotator A's user ID) ‚úÖ
   - reviewed_by_id: (Reviewer's user ID) ‚úÖ
   - reviewed_at: (timestamp when approved) ‚úÖ
   - status: 'approved' ‚úÖ
```

**Expected Result:**
- ‚úÖ Review is tracked automatically
- ‚úÖ Dataset table updates in real-time
- ‚úÖ Full audit trail maintained

---

## üìà STEP 6: TEST COMPLETION METRICS

### Test 6.1: Metrics Page Redirect

```
1. Login to Doccano
2. Go to your project
3. Click "‡ΩÇ‡Ωû‡Ω≤‡ºã‡ΩÇ‡æ≤‡ΩÑ‡Ω¶‡ºç" (Metrics) in left menu
4. Page should redirect to: /monlam/{project_id}/completion/ ‚úÖ
```

**Expected Result:**
- ‚úÖ Old metrics page is replaced
- ‚úÖ New completion matrix shows

### Test 6.2: Completion Matrix Data

```
Check the completion matrix for:

1. Annotator section:
   - ‚úÖ Shows all annotators
   - ‚úÖ Shows count of examples they annotated
   - ‚úÖ Shows % completion

2. Reviewer section:
   - ‚úÖ Shows all reviewers/approvers
   - ‚úÖ Shows count of examples they reviewed
   - ‚úÖ Shows % of examples approved vs rejected

3. Overall stats:
   - ‚úÖ Total examples
   - ‚úÖ Pending count
   - ‚úÖ In Progress count
   - ‚úÖ Submitted count
   - ‚úÖ Approved count
   - ‚úÖ Rejected count
```

**Expected Result:**
- ‚úÖ Data is accurate and up-to-date
- ‚úÖ Reflects current state of annotation_tracking table

---

## üîß STEP 7: TEST MONLAM UI PAGES

### Test 7.1: Enhanced Dataset Page

```
1. Navigate to: https://annotate.monlam.ai/monlam/{project_id}/dataset-enhanced/
2. Check if page loads ‚úÖ
3. Verify:
   - ‚úÖ Shows all examples with full data
   - ‚úÖ Shows annotated_by, reviewed_by, status columns
   - ‚úÖ "Back to Project" button works
   - ‚úÖ "Annotate" buttons work (if present)
```

### Test 7.2: Completion Dashboard

```
1. Navigate to: https://annotate.monlam.ai/monlam/{project_id}/completion/
2. Check if page loads ‚úÖ
3. Verify:
   - ‚úÖ Completion matrix displays
   - ‚úÖ Data is accurate
   - ‚úÖ "Back to Project" button works
```

### Test 7.3: Project Landing Page

```
1. Navigate to: https://annotate.monlam.ai/projects/{project_id}/
2. Check if page loads ‚úÖ
3. Verify:
   - ‚úÖ Shows project overview
   - ‚úÖ Quick stats display
   - ‚úÖ Links to dataset, metrics, etc. work
```

---

## ‚ö†Ô∏è TROUBLESHOOTING

### Issue: Columns Don't Appear

**Check:**
1. Open browser console (F12)
2. Look for errors related to `enhanceDatasetTable`
3. Check if API call to `/v1/projects/{id}/examples` succeeds
4. Verify `assignment_status`, `annotated_by`, `reviewed_by` are in API response

**Fix:**
- Clear browser cache
- Hard refresh (Ctrl+Shift+R)
- Check if `examples_serializer_patch.py` is applied

### Issue: Visibility Not Working

**Check:**
1. Server logs for `[Monlam Filter]` messages
2. Verify filter is registered:
   ```
   [Monlam Filter] ‚úÖ Added monlam_tracking.filters.AnnotationVisibilityFilter
   ```
3. Check user's role in project members

**Fix:**
- Ensure `monlam_tracking` app is in `INSTALLED_APPS`
- Verify `AppConfig.ready()` method runs
- Check if `DEFAULT_FILTER_BACKENDS` includes our filter

### Issue: Auto-Tracking Not Working

**Check:**
1. Server logs for `[Monlam Signals]` messages
2. Verify signals are connected:
   ```
   [Monlam Signals] ‚úÖ Connected tracking for Category
   [Monlam Signals] ‚úÖ Connected tracking for Span
   [Monlam Signals] ‚úÖ Connected tracking for TextLabel
   ```
3. Check if annotation save triggers signal

**Fix:**
- Ensure `monlam_tracking/apps.py` imports signals
- Verify `ready()` method runs
- Check if annotation models are correct (Category, Span, TextLabel)

### Issue: Migration Errors

**Check:**
```bash
python manage.py showmigrations assignment
```

**Fix:**
- If `0006_annotation_tracking_simple` is not checked:
  ```bash
  python manage.py migrate assignment --fake-initial
  ```
- If other migration errors, see `DATABASE_FIX_COMPLETE.md`

---

## üìä RESULTS TRACKING

### Test Results Summary

| Test                        | Status | Notes                        |
|-----------------------------|--------|------------------------------|
| Dataset Table Columns       | ‚¨ú     | (Mark ‚úÖ or ‚ùå after testing) |
| Annotator A Visibility      | ‚¨ú     |                              |
| Annotator B Visibility      | ‚¨ú     |                              |
| Reviewer Visibility         | ‚¨ú     |                              |
| Rejection Flow              | ‚¨ú     |                              |
| Example Locking             | ‚¨ú     |                              |
| Auto-Tracking (Annotate)    | ‚¨ú     |                              |
| Auto-Tracking (Review)      | ‚¨ú     |                              |
| Metrics Page Redirect       | ‚¨ú     |                              |
| Completion Matrix Data      | ‚¨ú     |                              |
| Enhanced Dataset Page       | ‚¨ú     |                              |
| Completion Dashboard        | ‚¨ú     |                              |
| Project Landing Page        | ‚¨ú     |                              |

---

## üîí POST-TESTING: SECURITY

### ‚ö†Ô∏è IMPORTANT: Rotate Database Password

Your database credentials were shared in this conversation. After testing:

1. Go to Render Dashboard
2. Navigate to your PostgreSQL database
3. Click "Info" or "Settings"
4. Find "Reset Password" or "Rotate Password"
5. Update the new password in your Doccano app's environment variables
6. Redeploy the app

**Current password:** `idwVrb3iVBs0edlU2Uh1zaQmjPCVpQQ6`  
**Action Required:** Change this! üîí

---

## ‚úÖ SIGN-OFF CHECKLIST

Before considering this complete, verify:

- [ ] All migrations applied successfully
- [ ] Server starts without errors
- [ ] Dataset table shows tracking columns
- [ ] Visibility filtering works for annotators
- [ ] Reviewers can see all examples
- [ ] Auto-tracking creates/updates records
- [ ] Example locking prevents conflicts
- [ ] Completion metrics display correctly
- [ ] Monlam UI pages load without errors
- [ ] Database password rotated (security)

---

## üéâ CONGRATULATIONS!

If all tests pass, you now have:

‚úÖ **Production-grade annotation tracking system**
‚úÖ **Expert visibility filtering** (prevents double-editing)
‚úÖ **Auto-tracking** (no manual data entry)
‚úÖ **Example locking** (prevents conflicts)
‚úÖ **Comprehensive metrics** (completion matrix)
‚úÖ **Clean database** (no migration issues)

**You're ready for production use! üöÄ**

---

**Questions or issues? Refer to:**
- `DATABASE_FIX_COMPLETE.md` - Database fix details
- `COMPLETE_IMPLEMENTATION_READY.md` - Full implementation guide
- `APPROVER_WORKFLOW_GUIDE.md` - Approval workflow details
- `MIGRATION_GUIDE.md` - Migration troubleshooting

**Happy annotating! üìù‚ú®**

