# üìã COMPLETE REQUIREMENTS - Monlam Doccano Customization

**Project:** Monlam Annotation Tools (Custom Doccano)  
**Goal:** Production-grade annotation tracking with Tibetan language support  
**Tech Stack:** Django (backend), Vue.js (frontend), PostgreSQL (database)

---

## üéØ CORE REQUIREMENTS

### **1. ANNOTATION TRACKING SYSTEM**

#### **1.1 Database Model: `AnnotationTracking`**

**Location:** Django model in `backend/`

**Fields:**
```python
class AnnotationTracking(models.Model):
    project = ForeignKey('projects.Project')
    example = ForeignKey('examples.Example')
    
    # Tracking fields
    annotated_by = ForeignKey(User, related_name='annotations_tracked', null=True)
    annotated_at = DateTimeField(null=True)
    reviewed_by = ForeignKey(User, related_name='reviews_tracked', null=True)
    reviewed_at = DateTimeField(null=True)
    
    # Status tracking
    status = CharField(max_length=20, choices=[
        ('pending', 'Pending'),
        ('in_progress', 'In Progress'),
        ('submitted', 'Submitted'),
        ('approved', 'Approved'),
        ('rejected', 'Rejected'),
    ], default='pending')
    
    # Review notes
    review_notes = TextField(blank=True, default='')
    
    # Example locking (prevent simultaneous editing)
    locked_by = ForeignKey(User, related_name='locked_examples', null=True)
    locked_at = DateTimeField(null=True)
    
    class Meta:
        unique_together = ('project', 'example')
        indexes = [
            Index(fields=['project', 'example']),
            Index(fields=['project', 'status']),
            Index(fields=['annotated_by']),
            Index(fields=['reviewed_by']),
            Index(fields=['locked_by']),
        ]
```

**Requirements:**
- ‚úÖ One tracking record per (project, example) pair
- ‚úÖ Tracks who annotated and who reviewed
- ‚úÖ Tracks timestamps for both actions
- ‚úÖ Stores review notes (especially for rejections)
- ‚úÖ Supports example locking to prevent conflicts

---

### **2. ROLE-BASED ACCESS CONTROL**

#### **2.1 User Roles**

| Role | Can Annotate | Can Review | Can See All | Can Manage |
|------|--------------|------------|-------------|------------|
| **Annotator** | ‚úÖ Yes | ‚ùå No | ‚ùå No | ‚ùå No |
| **Approver** | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes | ‚ùå No |
| **Project Manager** | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Limited |
| **Project Admin** | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Yes | ‚úÖ Full |

**Note:** Project Manager is essentially Approver + visibility of completion matrix.

#### **2.2 Permissions**

**Annotators:**
- Can annotate examples that are:
  - `pending` (not yet annotated by anyone)
  - `rejected` AND annotated by them (for revision)
- **Cannot see** examples annotated by others
- **Cannot see** examples that are `submitted`, `approved`, or rejected by others

**Approvers & Project Managers:**
- Can see **ALL** examples regardless of status
- Can approve or reject any submitted annotation
- Can add review notes

**Project Admins:**
- Full access to everything
- Can upload/download datasets
- Can manage project settings

---

### **3. VISIBILITY FILTERING (CRITICAL)**

#### **3.1 Annotator Visibility Rules**

**Rule:** Annotators should ONLY see:
1. Examples that are `pending` (unannotated)
2. Examples that are `rejected` AND annotated by them (for re-work)

**Rule:** Annotators should NOT see:
- Examples annotated by other annotators (prevents double-editing)
- Examples with status `submitted`, `approved`
- Examples with status `rejected` but annotated by someone else

**Implementation:** DRF Filter Backend on `ExampleListAPI`

```python
class AnnotationVisibilityFilter(BaseFilterBackend):
    def filter_queryset(self, request, queryset, view):
        user = request.user
        project_id = view.kwargs.get('project_id')
        
        # Superusers/Admins see everything
        if user.is_superuser:
            return queryset
        
        # Get user's role in project
        role = get_user_role(user, project_id)
        
        # Project Managers and Reviewers see all examples
        if role in ['project_manager', 'approver']:
            return queryset
        
        # Annotators: filtered visibility
        if role == 'annotator':
            return queryset.filter(
                Q(id__in=get_pending_examples(project_id)) |
                Q(id__in=get_rejected_by_user(project_id, user))
            )
        
        return queryset.none()
```

#### **3.2 Example Locking**

**Purpose:** Prevent two annotators from editing the same example simultaneously.

**Workflow:**
1. User opens an example ‚Üí Lock it (`locked_by` = user, `locked_at` = now)
2. Other users see "Locked by [username]" or cannot open it
3. User saves/closes ‚Üí Release lock (`locked_by` = NULL, `locked_at` = NULL)
4. Optional: Auto-release lock after timeout (e.g., 15 minutes of inactivity)

---

### **4. AUTO-TRACKING WITH DJANGO SIGNALS**

#### **4.1 Automatic Status Updates**

**Trigger:** When an annotator saves an annotation

**Action:**
```python
@receiver(post_save, sender=Category)  # or Span, TextLabel, etc.
def track_annotation(sender, instance, created, **kwargs):
    if created:
        tracking, _ = AnnotationTracking.objects.get_or_create(
            project=instance.project,
            example=instance.example,
            defaults={
                'annotated_by': instance.user,
                'annotated_at': timezone.now(),
                'status': 'submitted'
            }
        )
```

**Requirements:**
- ‚úÖ Automatically creates/updates tracking record when annotation is saved
- ‚úÖ Sets `annotated_by` to current user
- ‚úÖ Sets `annotated_at` to current timestamp
- ‚úÖ Changes status from `pending` ‚Üí `submitted`
- ‚úÖ No manual intervention needed

---

### **5. DATASET TABLE ENHANCEMENTS**

#### **5.1 Additional Columns**

**Location:** Dataset page (`/projects/{id}/dataset`)

**Add 3 columns at positions 4, 5, 6:**

| Position | Column Name | Data Source | Format |
|----------|-------------|-------------|--------|
| 4 | **Annotated By** | `AnnotationTracking.annotated_by.username` | Text (username) or "‚Äî" |
| 5 | **Reviewed By** | `AnnotationTracking.reviewed_by.username` | Text (username) or "‚Äî" |
| 6 | **Status** | `AnnotationTracking.status` | Badge with color |

**Status Badge Colors:**
- `pending`: Gray (#e0e0e0)
- `in_progress`: Blue (#2196f3)
- `submitted`: Orange (#ff9800)
- `approved`: Green (#4caf50)
- `rejected`: Red (#f44336)

#### **5.2 Data Source**

**Approach:** Extend Doccano's `ExampleSerializer` to include tracking data

```python
class EnhancedExampleSerializer(ExampleSerializer):
    annotated_by = SerializerMethodField()
    reviewed_by = SerializerMethodField()
    status = SerializerMethodField()
    
    class Meta(ExampleSerializer.Meta):
        fields = ExampleSerializer.Meta.fields + (
            'annotated_by', 'reviewed_by', 'status'
        )
    
    def get_annotated_by(self, obj):
        tracking = AnnotationTracking.objects.filter(example=obj).first()
        return tracking.annotated_by.username if tracking and tracking.annotated_by else None
    
    # Similar for reviewed_by and status
```

**Vue Component:** Modify the dataset table component to display these fields

---

### **6. APPROVE/REJECT WORKFLOW**

#### **6.1 UI Components**

**Location:** Annotation page (all types: STT, sequence labeling, etc.)

**For:** Approvers and Project Managers only

**Design:**
- Fixed position at bottom-right corner
- Floating card design with shadow
- Contains:
  1. **Status Display** (left): Shows current status and annotator
  2. **Approve Button** (middle): Green, "‚úì Approve"
  3. **Reject Button** (right): Red, "‚úó Reject"

**Example:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Status: SUBMITTED by john  [‚úì Approve] [‚úó Reject]  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **6.2 Approve Workflow**

**Trigger:** Reviewer clicks "‚úì Approve"

**Steps:**
1. Optional prompt: "Approval notes (optional):"
2. API call: `POST /v1/projects/{id}/tracking/{example_id}/approve/`
3. Update tracking:
   - `status` = 'approved'
   - `reviewed_by` = current user
   - `reviewed_at` = current timestamp
   - `review_notes` = user's notes
4. Success message: "‚úÖ Example approved successfully!"
5. Status display updates to "APPROVED by [reviewer]"
6. Example becomes hidden from annotators

#### **6.3 Reject Workflow**

**Trigger:** Reviewer clicks "‚úó Reject"

**Steps:**
1. **Required** prompt: "Rejection reason (required):"
2. Validate: Must provide reason (cannot be empty)
3. API call: `POST /v1/projects/{id}/tracking/{example_id}/reject/`
4. Update tracking:
   - `status` = 'rejected'
   - `reviewed_by` = current user
   - `reviewed_at` = current timestamp
   - `review_notes` = rejection reason
5. Success message: "‚úÖ Example rejected. Annotator will see it again for revision."
6. Example becomes visible to **original annotator only** (not other annotators)
7. Annotator can re-annotate and re-submit

#### **6.4 Auto-Update**

**Requirement:** Status display should update automatically when:
- User navigates to next/previous example
- Another reviewer approves/rejects
- Polling or WebSocket updates

---

### **7. COMPLETION METRICS DASHBOARD**

#### **7.1 Redirect**

**Requirement:** When user clicks "Metrics" in left menu, redirect to custom completion dashboard.

**From:** `/projects/{id}/metrics`  
**To:** `/monlam/{id}/completion/`

**Implementation:** Client-side redirect or Vue Router configuration

#### **7.2 Dashboard Content**

**Display:**

**Section 1: Overall Progress**
```
Total Examples: 100
Pending: 20 (20%)
In Progress: 10 (10%)
Submitted: 30 (30%)
Approved: 35 (35%)
Rejected: 5 (5%)
```

**Section 2: Annotator Performance**
```
| Annotator | Completed | Approved | Rejected | Success Rate |
|-----------|-----------|----------|----------|--------------|
| john      | 25        | 23       | 2        | 92%          |
| mary      | 30        | 28       | 2        | 93%          |
| ...       |           |          |          |              |
```

**Section 3: Reviewer Performance**
```
| Reviewer | Reviewed | Approved | Rejected | Approval Rate |
|----------|----------|----------|----------|---------------|
| admin    | 40       | 35       | 5        | 87.5%         |
| ...      |          |          |          |               |
```

**Section 4: Timeline** (optional)
- Line chart showing daily completion rate
- Bar chart showing status distribution over time

---

### **8. AUDIO AUTO-LOOP (STT Projects)**

#### **8.1 Requirement**

**For:** Speech-to-Text annotation pages only

**Behavior:**
1. When user opens an example with audio ‚Üí Audio plays automatically
2. Audio loops continuously (repeats when finished)
3. No visible loop button needed (automatic)
4. Audio plays ONLY on annotation pages
5. Audio does NOT play on dataset table page (would play all at once)

#### **8.2 Implementation**

**Vue Component:** Modify STT annotation component

```javascript
// In AudioPlayer component or similar
mounted() {
  if (this.$route.path.includes('/speech-to-text')) {
    this.$nextTick(() => {
      const audio = this.$refs.audioPlayer;
      if (audio) {
        audio.loop = true;
        audio.play().catch(e => {
          // Auto-play blocked, wait for user interaction
          document.addEventListener('click', () => audio.play(), { once: true });
        });
      }
    });
  }
}
```

**Requirements:**
- ‚úÖ Auto-play on load (if browser allows)
- ‚úÖ Loop continuously
- ‚úÖ Handle browser auto-play restrictions gracefully
- ‚úÖ Only on annotation pages, not dataset pages

---

### **9. TIBETAN LANGUAGE SUPPORT**

#### **9.1 Font**

**Font:** MonlamTBslim

**Requirement:**
- Replace Roboto font with MonlamTBslim throughout the application
- Ensure proper rendering of Tibetan script (‡Ωë‡Ωñ‡Ω¥‡ºã‡ΩÖ‡Ωì‡ºã)
- Font should be embedded/hosted locally (not CDN)

**Implementation:**
```css
@font-face {
  font-family: 'MonlamTBslim';
  src: url('/static/fonts/MonlamTBslim.woff2') format('woff2'),
       url('/static/fonts/MonlamTBslim.woff') format('woff'),
       url('/static/fonts/MonlamTBslim.ttf') format('truetype');
  font-weight: 100 900;
  font-style: normal;
  font-display: swap;
}

body, * {
  font-family: 'MonlamTBslim', 'Noto Sans Tibetan', sans-serif !important;
}
```

#### **9.2 UI Text**

**Requirement:** Tibetan text in menus and labels

**Examples:**
- "‡ΩÇ‡Ωû‡Ω≤‡ºã‡ΩÇ‡æ≤‡ΩÑ‡Ω¶‡ºç" (Dataset)
- Other Tibetan UI elements as specified

**Implementation:** Django i18n or direct template/component modification

---

### **10. BRANDING**

#### **10.1 Colors**

**Primary Colors:**
- Monlam Gold: `#B8963E`
- Monlam Gold Dark: `#9A7B32`
- Monlam Navy: `#1a1a2e`

**Apply to:**
- Navbar background: Navy
- Primary buttons: Gold
- Active menu items: Gold
- Links: Gold
- Progress bars: Gold

#### **10.2 Logo & Favicon**

**Requirement:**
- Replace Doccano branding with Monlam branding
- Custom favicon
- Logo in navbar

#### **10.3 Remove GitHub Links**

**Requirement:** Hide all GitHub-related buttons and links

```css
a[href*="github.com"],
button[class*="github"] {
  display: none !important;
}
```

---

## üèóÔ∏è ARCHITECTURE REQUIREMENTS

### **11. BACKEND STRUCTURE**

#### **11.1 Django Apps**

**Create custom Django apps:**

1. **`monlam_tracking`** - Annotation tracking system
   - Models: `AnnotationTracking`
   - Views/ViewSets: Tracking API endpoints
   - Filters: `AnnotationVisibilityFilter`
   - Signals: Auto-tracking on annotation save

2. **`monlam_ui`** - Custom UI components
   - Views: Completion dashboard
   - Templates: Custom pages
   - Static files: Fonts, images

#### **11.2 API Endpoints**

**Base URL:** `/v1/projects/{project_id}/tracking/`

**Endpoints:**
```
GET    /v1/projects/{id}/tracking/                    # List all tracking records
GET    /v1/projects/{id}/tracking/{example_id}/       # Get specific tracking
GET    /v1/projects/{id}/tracking/{example_id}/status/ # Get status only
POST   /v1/projects/{id}/tracking/{example_id}/approve/ # Approve example
POST   /v1/projects/{id}/tracking/{example_id}/reject/  # Reject example
POST   /v1/projects/{id}/tracking/mark-submitted/      # Mark as submitted
POST   /v1/projects/{id}/tracking/{example_id}/lock/   # Lock example
POST   /v1/projects/{id}/tracking/{example_id}/unlock/ # Unlock example
```

**Completion Metrics:**
```
GET    /monlam/{id}/completion/  # Completion dashboard page
GET    /v1/projects/{id}/tracking/summary/  # Summary stats (JSON)
GET    /v1/projects/{id}/tracking/annotators/  # Annotator performance
GET    /v1/projects/{id}/tracking/approvers/   # Reviewer performance
```

---

### **12. FRONTEND STRUCTURE**

#### **12.1 Vue Components to Modify**

**Dataset Table:**
- File: `frontend/components/dataset/DatasetTable.vue` (or similar)
- Modify: Add columns for `annotated_by`, `reviewed_by`, `status`
- Fetch: Enhanced example data from API

**Annotation Pages:**
- Files: `frontend/components/annotation/*` (STT, sequence labeling, etc.)
- Add: Approve/Reject button component
- Add: Status display component
- Add: Audio auto-loop for STT

**Metrics Page:**
- File: `frontend/pages/projects/_id/metrics.vue` (or similar)
- Modify: Redirect to `/monlam/{id}/completion/`
- Or: Replace with custom completion dashboard

**Menu:**
- File: `frontend/components/layout/Menu.vue` (or similar)
- Modify: Tibetan labels
- Add: Custom menu items if needed

#### **12.2 New Vue Components**

**`ApproveRejectButtons.vue`:**
```vue
<template>
  <div class="approve-reject-container">
    <div class="status-display">
      Status: {{ status }} by {{ annotatedBy }}
    </div>
    <v-btn color="success" @click="approve">
      ‚úì Approve
    </v-btn>
    <v-btn color="error" @click="reject">
      ‚úó Reject
    </v-btn>
  </div>
</template>

<script>
export default {
  props: ['exampleId', 'projectId'],
  data() {
    return {
      status: 'loading',
      annotatedBy: null
    }
  },
  methods: {
    async approve() {
      // API call to approve
    },
    async reject() {
      // API call to reject
    },
    async fetchStatus() {
      // API call to get status
    }
  },
  mounted() {
    this.fetchStatus()
  }
}
</script>
```

**`CompletionDashboard.vue`:**
- Display overall progress
- Display annotator performance table
- Display reviewer performance table
- Charts (optional)

---

## üß™ TESTING REQUIREMENTS

### **13. FUNCTIONAL TESTING**

#### **13.1 Annotator Workflow**

**Test Case 1: Basic Annotation**
```
1. Login as Annotator A
2. Go to project dataset
3. Should see only pending examples ‚úÖ
4. Click "Annotate" on Example #1
5. Add annotation (label/text/etc.)
6. Save
7. Go back to dataset
8. Example #1 should NOT be visible ‚úÖ
9. Status in tracking table should be "submitted" ‚úÖ
```

**Test Case 2: Visibility Isolation**
```
1. Login as Annotator A, annotate Example #5
2. Logout, login as Annotator B
3. Go to project dataset
4. Example #5 should NOT be visible to Annotator B ‚úÖ
5. Annotator B should only see unannotated examples ‚úÖ
```

**Test Case 3: Rejection & Re-work**
```
1. Annotator A submits Example #10
2. Login as Reviewer, reject Example #10 with notes
3. Login as Annotator A
4. Example #10 should NOW be visible ‚úÖ
5. Status shows "rejected" ‚úÖ
6. Can re-annotate and re-submit ‚úÖ
7. After re-submit, example disappears again ‚úÖ
```

#### **13.2 Reviewer Workflow**

**Test Case 4: Approve**
```
1. Login as Reviewer
2. Go to annotation page with submitted example
3. Approve/Reject buttons appear at bottom-right ‚úÖ
4. Status display shows "SUBMITTED by [username]" ‚úÖ
5. Click "Approve", add optional notes
6. Success message appears ‚úÖ
7. Status updates to "APPROVED" ‚úÖ
8. Example hidden from annotators ‚úÖ
```

**Test Case 5: Reject**
```
1. Login as Reviewer
2. Find submitted example
3. Click "Reject"
4. Prompt requires rejection reason ‚úÖ
5. Cannot submit empty reason ‚úÖ
6. After rejection, status = "REJECTED" ‚úÖ
7. Example visible to original annotator only ‚úÖ
```

#### **13.3 UI/UX Testing**

**Test Case 6: Dataset Table**
```
1. Go to dataset page
2. Verify columns:
   - Column 1, 2, 3: Original Doccano columns ‚úÖ
   - Column 4: "Annotated By" ‚úÖ
   - Column 5: "Reviewed By" ‚úÖ
   - Column 6: "Status" (colored badge) ‚úÖ
3. Verify data aligns with headers ‚úÖ
4. Verify status colors match specification ‚úÖ
```

**Test Case 7: Audio Loop**
```
1. Go to STT annotation page
2. Audio should play automatically (or after first click) ‚úÖ
3. Audio should loop continuously ‚úÖ
4. No visible loop button needed ‚úÖ
5. Go to dataset page
6. Audio should NOT play ‚úÖ
```

**Test Case 8: Metrics Redirect**
```
1. Go to project home
2. Click "Metrics" in left menu
3. Should redirect to /monlam/{id}/completion/ ‚úÖ
4. Should show completion dashboard ‚úÖ
5. No old metrics page ‚úÖ
```

---

## üöÄ DEPLOYMENT REQUIREMENTS

### **14. DOCKER & DOCKER COMPOSE**

**Requirement:** Maintain Docker-based deployment

**Files:**
- `Dockerfile` - Build instructions
- `docker-compose.yml` - Service orchestration
- `.dockerignore` - Exclude unnecessary files

**Services:**
- `backend` (Django/DRF)
- `frontend` (Vue.js, built into static files)
- `postgres` (Database)
- `nginx` (Reverse proxy, optional)

### **15. RENDER DEPLOYMENT**

**Platform:** Render.com

**Files:**
- `render.yaml` - Blueprint for Render services

**Services:**
- Web service (Docker-based)
- PostgreSQL database

**Environment Variables:**
- `DATABASE_URL`
- `SECRET_KEY`
- `DJANGO_SETTINGS_MODULE`
- AWS S3 credentials (for file storage)
- Other config as needed

**Post-Deploy:**
- Run migrations: `python manage.py migrate`
- Collect static files: `python manage.py collectstatic --noinput`
- Create superuser (if needed)

---

## üìä DATA REQUIREMENTS

### **16. DATABASE MIGRATIONS**

**Requirement:** All schema changes must be versioned via Django migrations

**Process:**
1. Make model changes
2. Run `python manage.py makemigrations`
3. Review migration file
4. Test locally
5. Deploy
6. Run `python manage.py migrate` on server

**Critical Migrations:**
- `0001_initial` - Initial AnnotationTracking model
- `0002_add_locking` - Add locked_by, locked_at fields
- `0003_add_indexes` - Performance indexes

### **17. EXISTING DATA**

**Requirement:** Do not break existing annotations

**Approach:**
- New tracking system should work alongside existing annotations
- Backfill tracking data for existing annotations (optional)
- Gracefully handle examples without tracking records (show as "pending")

---

## üéØ PERFORMANCE REQUIREMENTS

### **18. SCALABILITY**

**Requirements:**
- System should handle 1000+ examples per project
- System should handle 50+ concurrent users
- API responses < 500ms
- Page load times < 3s

**Optimizations:**
- Database indexes on frequently queried fields
- Pagination (default: 10-20 items per page)
- Caching (Redis, optional)
- Efficient queries (select_related, prefetch_related)

### **19. BROWSER SUPPORT**

**Requirements:**
- Chrome/Edge (latest)
- Firefox (latest)
- Safari (latest)
- Mobile browsers (optional)

---

## üîê SECURITY REQUIREMENTS

### **20. AUTHENTICATION & AUTHORIZATION**

**Requirements:**
- Use Doccano's existing auth system
- Enforce role-based permissions at API level
- Verify user permissions before every action
- Prevent privilege escalation

**Validation:**
- Annotators cannot approve/reject
- Users cannot modify other users' annotations
- Example locking prevents concurrent edits

### **21. DATA INTEGRITY**

**Requirements:**
- Unique constraint on (project, example) for tracking
- Foreign key constraints to prevent orphaned records
- Atomic transactions for approve/reject actions
- Validation on API inputs (e.g., rejection reason required)

---

## üìö DOCUMENTATION REQUIREMENTS

### **22. CODE DOCUMENTATION**

**Requirements:**
- Docstrings for all models, views, serializers
- Comments for complex logic
- README files in each custom app directory
- API documentation (Swagger/OpenAPI, optional)

### **23. USER DOCUMENTATION**

**Requirements:**
- User guide for annotators
- User guide for reviewers
- Admin guide for project setup
- Troubleshooting guide

---

## ‚úÖ SUCCESS CRITERIA

### **24. DEFINITION OF DONE**

**A feature is complete when:**
1. ‚úÖ Code is written and tested
2. ‚úÖ Unit tests pass (if applicable)
3. ‚úÖ Manual testing confirms functionality
4. ‚úÖ Code is reviewed
5. ‚úÖ Documentation is updated
6. ‚úÖ Deployed to staging
7. ‚úÖ User acceptance testing passes
8. ‚úÖ Deployed to production

**Overall project is complete when:**
1. ‚úÖ All requirements implemented
2. ‚úÖ All tests pass
3. ‚úÖ No critical bugs
4. ‚úÖ Performance requirements met
5. ‚úÖ Documentation complete
6. ‚úÖ User training complete (if needed)
7. ‚úÖ Production deployment successful
8. ‚úÖ Stakeholder sign-off

---

## üîÑ WORKFLOW SUMMARY

### **25. END-TO-END WORKFLOW**

**Annotator Journey:**
```
1. Login ‚Üí Dashboard
2. Select project ‚Üí See only pending examples
3. Click "Annotate" ‚Üí Annotation page (audio loops if STT)
4. Add annotation ‚Üí Save
5. Example disappears from view (status: submitted)
6. Move to next pending example
7. If reviewer rejects ‚Üí Example reappears with notes
8. Fix and re-submit ‚Üí Example disappears again
```

**Reviewer Journey:**
```
1. Login ‚Üí Dashboard
2. Select project ‚Üí See ALL examples
3. Filter by status: "submitted"
4. Click on submitted example ‚Üí Annotation page
5. Review annotation ‚Üí Buttons appear at bottom-right
6. Approve (with optional notes) OR Reject (with required notes)
7. Status updates ‚Üí Example hidden from annotators (if approved)
8. Move to next submitted example
```

**Project Manager Journey:**
```
1. Login ‚Üí Dashboard
2. Select project
3. Click "Metrics" ‚Üí Redirects to completion dashboard
4. View overall progress
5. View annotator performance table
6. View reviewer performance table
7. Identify bottlenecks or issues
8. Can also review examples like Approver
```

**Project Admin Journey:**
```
1. All of the above +
2. Upload dataset
3. Download results
4. Manage project settings
5. Add/remove members
6. Assign roles
```

---

## üé® UI/UX WIREFRAMES (Conceptual)

### **26. DATASET TABLE**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ID  ‚îÇ  Text/Data  ‚îÇ  ...  ‚îÇ Annotated By ‚îÇ Reviewed By ‚îÇ Status ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1   ‚îÇ  ‡Ω¶‡ΩÑ‡Ω¶‡ºã‡Ω¢‡æí‡æ±‡Ω¶...  ‚îÇ  ...  ‚îÇ  john        ‚îÇ  admin      ‚îÇ ‚úÖ APPROVED ‚îÇ
‚îÇ  2   ‚îÇ  ‡Ωñ‡æ±‡ΩÑ‡ºã‡ΩÜ‡Ω¥‡Ωñ...  ‚îÇ  ...  ‚îÇ  mary        ‚îÇ  ‚Äî          ‚îÇ üü† SUBMITTED ‚îÇ
‚îÇ  3   ‚îÇ  ‡Ω¶‡Ω∫‡Ωò‡Ω¶‡ºã‡Ωë‡Ωî‡Ω†... ‚îÇ  ...  ‚îÇ  ‚Äî           ‚îÇ  ‚Äî          ‚îÇ ‚ö™ PENDING ‚îÇ
‚îÇ  4   ‚îÇ  ‡ΩÜ‡Ωº‡Ω¶‡ºã‡Ωâ‡Ω≤‡Ωë...  ‚îÇ  ...  ‚îÇ  john        ‚îÇ  admin      ‚îÇ ‚ùå REJECTED ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **27. ANNOTATION PAGE (WITH APPROVE/REJECT)**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚Üê Previous  |  Project Name  |  Next ‚Üí                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                ‚îÇ
‚îÇ  [Audio Player - plays automatically, loops]                  ‚îÇ
‚îÇ  ‚ñ∂ ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 0:45 / 1:30                          ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  Transcript:                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  ‡Ω¶‡ΩÑ‡Ω¶‡ºã‡Ω¢‡æí‡æ±‡Ω¶‡ºã‡Ωñ‡Ω¶‡æü‡Ωì‡ºã‡Ωî‡ºã‡Ω¢‡Ω≤‡Ωì‡ºã‡Ωî‡Ωº‡ºã‡ΩÜ‡Ω∫‡ºç                              ‚îÇ
‚îÇ  ‚îÇ  ‡Ωñ‡æ±‡ΩÑ‡ºã‡ΩÜ‡Ω¥‡Ωñ‡ºã‡Ω¶‡Ω∫‡Ωò‡Ω¶‡ºã‡Ωë‡Ωî‡Ω†‡Ω≤‡ºã‡Ω¶‡Ω∫‡Ωò‡Ω¶‡ºç                               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  Labels: [Category Dropdown] [Add Label Button]               ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ                   [Save & Next] [Skip]                         ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ                                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                                      ‚îÇ Status: SUBMITTED  ‚îÇ   ‚îÇ
‚îÇ                                      ‚îÇ   by john          ‚îÇ   ‚îÇ
‚îÇ                                      ‚îÇ                    ‚îÇ   ‚îÇ
‚îÇ                                      ‚îÇ  [‚úì Approve]       ‚îÇ   ‚îÇ
‚îÇ                                      ‚îÇ  [‚úó Reject]        ‚îÇ   ‚îÇ
‚îÇ                                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                      ‚Üë Bottom-right, fixed    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **28. COMPLETION DASHBOARD**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Project: ‡Ωò‡Ωº‡Ωì‡ºã‡Ω£‡Ωò‡ºç - ‡Ωë‡Ωî‡Ω∫‡ºã‡ΩÇ‡æ≤‡ΩÑ‡Ω¶‡ºç  |  Completion Matrix       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                ‚îÇ
‚îÇ  üìä Overall Progress                                          ‚îÇ
‚îÇ  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 75% Complete                            ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  Total: 100  |  Pending: 10  |  Submitted: 15  |  Approved: 75 ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Annotator Performance                               ‚îÇ    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îÇ
‚îÇ  ‚îÇ Name     ‚îÇ Completed‚îÇ Approved ‚îÇ Rejected ‚îÇ Rate ‚îÇ    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îÇ
‚îÇ  ‚îÇ john     ‚îÇ    25    ‚îÇ    23    ‚îÇ     2    ‚îÇ 92%  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ mary     ‚îÇ    30    ‚îÇ    28    ‚îÇ     2    ‚îÇ 93%  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ tashi    ‚îÇ    20    ‚îÇ    19    ‚îÇ     1    ‚îÇ 95%  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Reviewer Performance                                ‚îÇ    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îÇ
‚îÇ  ‚îÇ Name     ‚îÇ Reviewed ‚îÇ Approved ‚îÇ Rejected ‚îÇ Rate ‚îÇ    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îÇ
‚îÇ  ‚îÇ admin    ‚îÇ    40    ‚îÇ    35    ‚îÇ     5    ‚îÇ 87%  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ reviewer1‚îÇ    35    ‚îÇ    33    ‚îÇ     2    ‚îÇ 94%  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                ‚îÇ
‚îÇ  [Export Report] [Back to Project]                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üö® CRITICAL NOTES

### **29. THINGS THAT MUST NOT BREAK**

**Do NOT break:**
- ‚úÖ Existing Doccano annotation functionality
- ‚úÖ Existing project management
- ‚úÖ Existing user authentication
- ‚úÖ Existing data export/import
- ‚úÖ Existing API endpoints (add new ones, don't modify existing)

**Approach:**
- Extend, don't replace
- Add features alongside existing ones
- Maintain backward compatibility
- Test thoroughly before deployment

### **30. THINGS THAT NEED SPECIAL ATTENTION**

**Critical Areas:**
1. **Visibility Filtering:** Most important feature, prevents double-editing
2. **Audio Loop:** Must work reliably on STT pages
3. **Dataset Table Columns:** Must align perfectly, no misalignment
4. **Approve/Reject Buttons:** Must appear reliably, must get correct example ID
5. **Metrics Redirect:** Must work on first click, no refresh needed

**Known Challenges:**
- JavaScript patching is fragile (that's why we're moving to Vue)
- Vue Router can intercept redirects
- Audio auto-play is restricted by browsers
- Getting current example ID from Vue state can be tricky
- Race conditions in table enhancement

---

## üéì TECHNICAL EXPERTISE REQUIRED

### **31. SKILLS NEEDED**

**Backend:**
- Django framework (models, views, serializers)
- Django REST Framework (viewsets, filters, permissions)
- PostgreSQL (indexes, constraints, queries)
- Django signals
- Python best practices

**Frontend:**
- Vue.js 2/3 (components, Vuex, Vue Router)
- JavaScript ES6+
- Vuetify (or whatever UI framework Doccano uses)
- CSS/SCSS
- Webpack/Vite (build tools)

**DevOps:**
- Docker & Docker Compose
- Render.com deployment
- Environment variables
- Static file serving
- Database migrations

**Understanding:**
- Doccano architecture
- SPA (Single Page Application) patterns
- RESTful API design
- Role-based access control
- Internationalization (i18n)

---

## üìû HANDOFF INFORMATION

### **32. CURRENT STATE**

**Git Repository:** https://github.com/MonlamAI/Monlam-Annotation-Tools

**Current Live Commit:** `318f73b` (on Render)

**Latest Commit:** `b9b9311` (on GitHub, but broken)

**Reason for Rollback:**
- Commits after `318f73b` broke audio loop
- JavaScript patching approach is too fragile
- Need proper Vue.js implementation

**What Works at 318f73b:**
- ‚úÖ Audio loop (confirmed working)
- ‚úÖ Approve/reject buttons (confirmed working)
- ‚ùì Dataset table columns (need to test)
- ‚ùì Metrics redirect (need to test)

### **33. WHAT TO START WITH**

**Phase 1: Foundation (Week 1)**
1. Clone Doccano source code
2. Set up local development environment
3. Understand Doccano's Vue structure
4. Identify Vue components to modify
5. Create custom Django apps (`monlam_tracking`, `monlam_ui`)
6. Set up database models and migrations

**Phase 2: Backend (Week 2)**
1. Implement `AnnotationTracking` model
2. Create API endpoints (approve, reject, status)
3. Implement visibility filter
4. Set up Django signals for auto-tracking
5. Extend `ExampleSerializer`
6. Test API endpoints

**Phase 3: Frontend (Week 3)**
1. Modify dataset table component (add columns)
2. Create approve/reject buttons component
3. Implement audio auto-loop in STT component
4. Create completion dashboard component
5. Set up metrics redirect
6. Apply Tibetan font and branding

**Phase 4: Testing & Deployment (Week 4)**
1. Unit tests (backend)
2. Integration tests
3. Manual testing (all workflows)
4. Docker build and test
5. Deploy to staging
6. User acceptance testing
7. Deploy to production

---

## ‚úÖ FINAL CHECKLIST

### **34. BEFORE HANDING OFF**

**Provide to New Agent:**
- ‚úÖ This complete requirements document
- ‚úÖ Access to GitHub repository
- ‚úÖ Access to Render account (or credentials)
- ‚úÖ Database credentials
- ‚úÖ Current working commit (`318f73b`)
- ‚úÖ Sample data or test project

**New Agent Should:**
1. ‚úÖ Read this document thoroughly
2. ‚úÖ Set up local development environment
3. ‚úÖ Clone Doccano source code
4. ‚úÖ Understand Doccano architecture
5. ‚úÖ Create project plan with milestones
6. ‚úÖ Start with Phase 1 (Foundation)
7. ‚úÖ Communicate progress regularly
8. ‚úÖ Test each feature thoroughly
9. ‚úÖ Deploy incrementally
10. ‚úÖ Document all changes

---

## üéØ SUCCESS METRICS

### **35. HOW TO MEASURE SUCCESS**

**Technical Metrics:**
- ‚úÖ All 34 requirements implemented
- ‚úÖ All tests pass
- ‚úÖ No critical bugs
- ‚úÖ API response time < 500ms
- ‚úÖ Page load time < 3s
- ‚úÖ Zero data loss or corruption

**User Metrics:**
- ‚úÖ Annotators can annotate without seeing others' work
- ‚úÖ Reviewers can approve/reject easily
- ‚úÖ Project managers have full visibility
- ‚úÖ Audio loop works reliably
- ‚úÖ Dataset table shows correct data
- ‚úÖ System is intuitive and easy to use

**Business Metrics:**
- ‚úÖ Annotation throughput increases
- ‚úÖ Annotation quality improves
- ‚úÖ Fewer conflicts and duplicate work
- ‚úÖ Better project management visibility
- ‚úÖ Stakeholder satisfaction

---

## üöÄ LET'S DO THIS RIGHT!

**This is a comprehensive specification for a production-grade Doccano customization.**

**Hand this to your new agent along with:**
- Current codebase at `318f73b`
- Access to development environment
- Any additional context or examples

**The new agent should have expertise in:**
- Django + DRF
- Vue.js
- PostgreSQL
- Docker
- Doccano architecture

**Good luck! üéâ**

---

**Document Version:** 1.0  
**Last Updated:** January 7, 2026  
**Author:** Comprehensive requirements compilation  
**Next Steps:** Hand off to new agent for proper Vue.js implementation

